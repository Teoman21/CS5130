{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e89cd40",
   "metadata": {},
   "source": [
    "### Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b3cba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 10)\n",
      "\n",
      "Data types:\n",
      "customer_id             int64\n",
      "age                     int64\n",
      "region                 object\n",
      "customer_type          object\n",
      "total_purchases         int64\n",
      "total_spent           float64\n",
      "avg_purchase_value    float64\n",
      "satisfaction_score    float64\n",
      "account_status         object\n",
      "referral_source        object\n",
      "dtype: object\n",
      "\n",
      "Memory usage (before optimization): 2.90 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load with default settings\n",
    "df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Check the shape\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")\n",
    "\n",
    "# Measure memory usage\n",
    "memory_before = df.memory_usage(deep=True).sum() / 1024**2  # Convert to MB\n",
    "print(f\"\\nMemory usage (before optimization): {memory_before:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19829be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only needed columns\n",
    "needed_columns = ['customer_id', 'age', 'region', 'customer_type', 'total_spent', 'satisfaction_score']\n",
    "\n",
    "# Define optimal data types\n",
    "dtype_map = {\n",
    "    'customer_id': 'int32',\n",
    "    'age': 'int8',\n",
    "    'region': 'category',\n",
    "    'customer_type': 'category',\n",
    "    'total_spent': 'float32',\n",
    "    'satisfaction_score': 'float32'\n",
    "}\n",
    "\n",
    "# Load with optimizations\n",
    "df_optimized = pd.read_csv(\n",
    "    'customer_data.csv',\n",
    "    usecols=needed_columns,\n",
    "    dtype=dtype_map\n",
    ")\n",
    "\n",
    "# Measure memory usage after optimization\n",
    "memory_after = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nMemory usage (after optimization): {memory_after:.2f} MB\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement_pct = ((memory_before - memory_after) / memory_before) * 100\n",
    "print(f\"Memory improvement: {improvement_pct:.2f}%\")\n",
    "\n",
    "# Check the optimized DataFrame\n",
    "print(f\"\\nOptimized shape: {df_optimized.shape}\")\n",
    "print(f\"\\nOptimized data types:\\n{df_optimized.dtypes}\")\n",
    "print(f\"\\nFirst few rows:\\n{df_optimized.head()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66c6d2f",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68c6fc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memory usage (after optimization): 0.14 MB\n",
      "Memory improvement: 95.03%\n",
      "\n",
      "Optimized shape: (10000, 6)\n",
      "\n",
      "Optimized data types:\n",
      "customer_id              int32\n",
      "age                       int8\n",
      "region                category\n",
      "customer_type         category\n",
      "total_spent            float32\n",
      "satisfaction_score     float32\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n",
      "   customer_id  age     region customer_type  total_spent  satisfaction_score\n",
      "0            1   56  Northeast          Gold   246.130005                 1.1\n",
      "1            2   69  Northeast        Silver  7928.109863                 3.5\n",
      "2            3   46    Midwest        Bronze    20.570000                 3.8\n",
      "3            4   32  Southeast        Bronze  3439.129883                 2.6\n",
      "4            5   60       West      Platinum  4945.830078                 1.7\n"
     ]
    }
   ],
   "source": [
    "# Select only needed columns\n",
    "needed_columns = ['customer_id', 'age', 'region', 'customer_type', 'total_spent', 'satisfaction_score']\n",
    "\n",
    "# Define optimal data types\n",
    "dtype_map = {\n",
    "    'customer_id': 'int32',\n",
    "    'age': 'int8',\n",
    "    'region': 'category',\n",
    "    'customer_type': 'category',\n",
    "    'total_spent': 'float32',\n",
    "    'satisfaction_score': 'float32'\n",
    "}\n",
    "\n",
    "# Load with optimizations\n",
    "df_optimized = pd.read_csv(\n",
    "    'customer_data.csv',\n",
    "    usecols=needed_columns,\n",
    "    dtype=dtype_map\n",
    ")\n",
    "\n",
    "# Measure memory usage after optimization\n",
    "memory_after = df_optimized.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"\\nMemory usage (after optimization): {memory_after:.2f} MB\")\n",
    "\n",
    "# Calculate improvement\n",
    "improvement_pct = ((memory_before - memory_after) / memory_before) * 100\n",
    "print(f\"Memory improvement: {improvement_pct:.2f}%\")\n",
    "\n",
    "# Check the optimized DataFrame\n",
    "print(f\"\\nOptimized shape: {df_optimized.shape}\")\n",
    "print(f\"\\nOptimized data types:\\n{df_optimized.dtypes}\")\n",
    "print(f\"\\nFirst few rows:\\n{df_optimized.head()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c69ff9c",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "\n",
    "Info to Submit \n",
    "Metric\tYour Result\n",
    "Memory usage before optimization\t2.90 MB\n",
    "Memory usage after optimization\t0.14 MB\n",
    "Memory reduction percentage\t95.03 %\n",
    "Number of columns (before)\tshape: (10000, 10)\n",
    "Number of columns (after)\tshape:(10000, 6)\n",
    "\n",
    "Q1: Selective column loading had the biggest effect because dropping four unneeded columns immediately shrank the dataset from 10 to 6 fields, while the dtype tweaks only squeezed a bit more from the remaining columns; fewer columns simply means dramatically less data to store. Dtype optimization still mattered, but it’s more of a fine tuning step once you have already limited the column set.\n",
    "\n",
    "Q2: On a project with data 100× larger, loading only the required columns would keep notebooks responsive and prevent running out of RAM during exploration. The lighter dtypes would let me keep more intermediate DataFrames in memory, so I could iterate faster without constantly sampling or spilling to disk, making the whole workflow smoother.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
